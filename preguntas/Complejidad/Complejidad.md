# Preguntas sobre Complejidad AlgorÃ­tmica (Big O)

---

## 1. Â¿QuÃ© significa que un algoritmo tenga complejidad O(n)?

Un algoritmo O(n) significa que su tiempo de ejecuciÃ³n crece linealmente con respecto al tamaÃ±o de la entrada.

- Si la entrada tiene 10 elementos, harÃ¡ aproximadamente 10 operaciones.
- Si tiene 1.000 elementos, harÃ¡ 1.000 operaciones.

### Ejemplo:
```python
def buscar_elemento(lista, objetivo):
    for x in lista:
        if x == objetivo:
            return True
    return False
```

 ## 2. Â¿CuÃ¡l es la complejidad de buscar un elemento en una lista vs. en un diccionario?

| Estructura  | Complejidad de bÃºsqueda | NotaciÃ³n |
|-------------|--------------------------|----------|
| Lista       | Lineal                   | O(n)     |
| Diccionario | Constante promedio       | O(1)     |

**Nota:** En casos extremos de colisiones, un diccionario puede degradarse a `O(n)`, pero eso es raro con un buen sistema de *hashing*.

## 3. Â¿QuÃ© complejidad tiene recorrer una lista de listas (matriz) de n Ã— m elementos?

La complejidad es `O(n Ã— m)`, porque hay que iterar sobre cada fila y cada columna dentro de cada fila.

ðŸ§ª **Ejemplo:**

```python
def sumar_matriz(matriz):
    suma = 0
    for fila in matriz:
        for valor in fila:
            suma += valor
    return suma
```

## 4. Â¿CuÃ¡l es la complejidad del siguiente fragmento de cÃ³digo?
```python
for i in range(n):
    for j in range(n):
        print(i, j)
```
Cada iteraciÃ³n externa se repite n veces, y dentro de ella hay otras n repeticiones â†’ n Ã— n.

## Pregunta 5: Â¿QuÃ© complejidad tiene una bÃºsqueda binaria en una lista ordenada?
O(log n)
Porque en cada paso se reduce el tamaÃ±o del problema a la mitad.

```python
def busqueda_binaria(lista, objetivo):
    izquierda, derecha = 0, len(lista) - 1
    while izquierda <= derecha:
        medio = (izquierda + derecha) // 2
        if lista[medio] == objetivo:
            return medio
        elif lista[medio] < objetivo:
            izquierda = medio + 1
        else:
            derecha = medio - 1
    return -1
```


## 6. Â¿CuÃ¡l es el impacto de la recursividad en la complejidad temporal?

- La recursividad puede ser poderosa, pero tambiÃ©n costosa si no se optimiza.
- Muchas funciones recursivas tienen complejidad exponencial si recalculan subproblemas.

### Ejemplo clÃ¡sico: Fibonacci

```python
def fib(n):
    if n <= 1:
        return n
    return fib(n - 1) + fib(n - 2)
```

Complejidad: O(2â¿) â†’ ineficiente para valores grandes.

SoluciÃ³n: memoizaciÃ³n o programaciÃ³n dinÃ¡mica
```python
def fib_dp(n):
    memo = [0, 1]
    for i in range(2, n+1):
        memo.append(memo[i-1] + memo[i-2])
    return memo[n]
```

Complejidad: O(n)


## 7. Â¿CuÃ¡ndo conviene usar una tabla hash (`dict`) en lugar de una lista?

Usa un **diccionario (tabla hash)** cuando:

- NecesitÃ¡s bÃºsquedas rÃ¡pidas por clave â†’ O(1) promedio.
- Hay necesidad de acceder a elementos por identificador.

Usa una **lista** cuando:

- El orden importa o es secuencial.
- Se necesita recorrer todos los elementos en orden.

### Ejemplo:

```python
# BÃºsqueda en lista (O(n))
for producto in productos:
    if producto.id == 5:
        return producto

# BÃºsqueda en dict (O(1))
productos_por_id = {p.id: p for p in productos}
return productos_por_id[5]
```


## 8. Â¿QuÃ© complejidad tienen las funciones `map`, `filter` y `reduce` en listas?

Todas estas funciones recorren la lista **una sola vez**, por lo que tienen complejidad **O(n)**.

- `map`: aplica una funciÃ³n a cada elemento â†’ O(n)
- `filter`: evalÃºa una condiciÃ³n sobre cada elemento â†’ O(n)
- `reduce`: combina elementos usando una operaciÃ³n acumulativa â†’ O(n)

### Ejemplo en Python:
```python
nombres = ["Ana", "Luis", "Carlos"]

# map
mayusculas = list(map(str.upper, nombres))

# filter
largos = list(filter(lambda x: len(x) > 3, nombres))

# reduce
from functools import reduce
total_letras = reduce(lambda acc, x: acc + len(x), nombres, 0)
```

Nota:
Aunque O(n), estas funciones son muy eficientes porque estÃ¡n optimizadas internamente.


## 9. Â¿QuÃ© prefieres entre un algoritmo O(n log n) y uno O(nÂ²), y por quÃ©?

En general, un algoritmo **O(n log n)** es mÃ¡s eficiente que uno **O(nÂ²)**, especialmente cuando `n` (el tamaÃ±o de la entrada) es grande.

### ComparaciÃ³n prÃ¡ctica:

| n     | n log n (base 2) | nÂ²     |
|-------|------------------|--------|
| 10    | ~33              | 100    |
| 100   | ~664             | 10,000 |
| 1,000 | ~9,966           | 1,000,000 |

â†’ A medida que `n` crece, la diferencia se vuelve enorme.

### Ejemplo real:
- O(nÂ²): burbuja, selecciÃ³n, inserciÃ³n (ordenamiento lentos).
- O(n log n): mergesort, heapsort (ordenamiento eficientes).

> Incluso si O(nÂ²) puede ser mÃ¡s simple de implementar, **en producciÃ³n se prioriza la eficiencia y escalabilidad**.

Siempre que sea posible, **prefiere algoritmos con mejor complejidad asintÃ³tica**, especialmente en sistemas con muchos datos o usuarios concurrentes.

## 10. Â¿QuÃ© representa la notaciÃ³n Big O y por quÃ© es importante en programaciÃ³n backend?

La **notaciÃ³n Big O** describe el **crecimiento del tiempo o espacio** que requiere un algoritmo en funciÃ³n del tamaÃ±o de entrada `n`. Es una forma de analizar la eficiencia algorÃ­tmica.

### Â¿Por quÃ© es importante?
- Permite comparar algoritmos de forma teÃ³rica.
- Ayuda a anticipar problemas de rendimiento en sistemas con muchos usuarios o datos.
- Es clave para tomar decisiones tÃ©cnicas informadas.

### Ejemplos comunes:

| Complejidad | Nombre           | Ejemplo                          |
|-------------|------------------|----------------------------------|
| O(1)        | Constante        | Acceso a un elemento en un array |
| O(log n)    | LogarÃ­tmica      | BÃºsqueda binaria                 |
| O(n)        | Lineal           | Recorrer un arreglo              |
| O(n log n)  | Lineal logarÃ­tmica | Mergesort, Quicksort (mejor caso) |
| O(nÂ²)       | CuadrÃ¡tica       | Burbujas, selecciÃ³n, inserciÃ³n   |

### Ejemplo en cÃ³digo:

```python
# O(n): recorre una lista
def suma(lista):
    total = 0
    for num in lista:
        total += num
    return total
```

### ConsideraciÃ³n:

Big O no mide tiempos reales, sino crecimiento relativo. Depende del peor caso (salvo que se aclare lo contrario).

> Dominar Big O permite escribir cÃ³digo mÃ¡s escalable y tomar mejores decisiones en el diseÃ±o backend.

## 11. Â¿CuÃ¡l es la complejidad del siguiente cÃ³digo y por quÃ©?

```python
def buscar_pares(lista):
    for i in lista:
        for j in lista:
            if (i + j) % 2 == 0:
                print(i, j)
```

El cÃ³digo tiene dos bucles anidados que recorren la lista completa.

Si la lista tiene n elementos, el nÃºmero total de combinaciones es n * n â†’ O(nÂ²).


### AnÃ¡lisis:

| LÃ­nea                 | OperaciÃ³n                         | Complejidad |
|----------------------|-----------------------------------|-------------|
| `for i in lista:`    | Recorre `n` elementos             | O(n)        |
| `for j in lista:`    | Anidado, se ejecuta por cada `i`  | O(n)        |
| `print(i, j)`        | OperaciÃ³n constante               | O(1)        |


â†’ Complejidad total: O(nÂ²)

### Â¿CÃ³mo podrÃ­a optimizarse?

Si no necesitas combinaciones repetidas ((i,j) y (j,i)), puedes usar for j in lista[i+1:] para reducir a aproximadamente la mitad las iteraciones.

Pero la complejidad seguirÃ­a siendo O(nÂ²), solo con un mejor coeficiente.


> Saber leer y analizar cÃ³digo te permite anticipar cuellos de botella en tiempo de ejecuciÃ³n.

## 12. Â¿CuÃ¡l es la complejidad de las operaciones bÃ¡sicas en un diccionario (hashmap) y por quÃ©?

Los **diccionarios** (tambiÃ©n llamados **hashmaps** o **tablas hash**) permiten almacenar y acceder a datos por clave. En la mayorÃ­a de los lenguajes modernos (como Python, JavaScript, Java), estÃ¡n implementados con **hash tables**.

### Complejidades comunes:

| OperaciÃ³n         | Complejidad Promedio | Complejidad Peor Caso |
|-------------------|----------------------|------------------------|
| Insertar (`put`)  | O(1)                 | O(n) (en caso de colisiones extremas) |
| Acceder (`get`)   | O(1)                 | O(n)                   |
| Eliminar (`del`)  | O(1)                 | O(n)                   |

> En la prÃ¡ctica, con buenas funciones de hash y mecanismos de resoluciÃ³n de colisiones, el rendimiento se mantiene cercano a **O(1)**.

### Ejemplo en Python:

```python
usuarios = {"ana": 25, "juan": 30}
usuarios["ana"]  # acceso en O(1)
usuarios["carlos"] = 22  # inserciÃ³n en O(1)
```

### Consideraciones:

La eficiencia depende de la funciÃ³n hash y la implementaciÃ³n interna.

En situaciones donde hay muchas colisiones, el rendimiento puede degradarse.


> Los diccionarios son una de las estructuras mÃ¡s eficientes para bÃºsquedas, pero no siempre son la mejor opciÃ³n si se necesita orden o evitar colisiones.

## 13 Â¿QuÃ© es la complejidad espacial y cÃ³mo se diferencia de la complejidad temporal?

La **complejidad espacial** mide cuÃ¡nta **memoria adicional** necesita un algoritmo para ejecutarse, en funciÃ³n del tamaÃ±o de la entrada.

### ComparaciÃ³n:

| Tipo de complejidad | QuÃ© mide                    | Ejemplo de unidad         |
|---------------------|-----------------------------|---------------------------|
| Temporal            | Tiempo de ejecuciÃ³n         | Operaciones / pasos       |
| Espacial            | Memoria utilizada           | Variables, arreglos, etc. |

### Ejemplo simple:

```python
def suma(lista):
    total = 0      # O(1)
    for num in lista:
        total += num
    return total
```

Complejidad temporal: O(n) (por el bucle)

Complejidad espacial: O(1) (solo una variable total)


### Ejemplo con mayor uso de memoria:

```python
def duplicar(lista):
    nueva = []
    for x in lista:
        nueva.append(x * 2)
    return nueva
```

AquÃ­, la complejidad espacial es O(n), porque se crea una nueva lista del mismo tamaÃ±o que la original.


### Â¿Por quÃ© es importante?

En sistemas con memoria limitada (embedded, mÃ³viles).

Cuando se procesan grandes volÃºmenes de datos.

Para optimizar algoritmos mÃ¡s allÃ¡ del tiempo.


> Una soluciÃ³n rÃ¡pida que consume demasiada memoria puede no ser viable en producciÃ³n. El equilibrio entre tiempo y espacio es clave.

## 14. Â¿CuÃ¡l es la complejidad temporal de los algoritmos de ordenamiento mÃ¡s comunes?

A continuaciÃ³n se muestra una tabla con la complejidad temporal de algunos algoritmos de ordenamiento conocidos:

| Algoritmo          | Mejor caso       | Promedio         | Peor caso          | Estable |
|--------------------|------------------|------------------|--------------------|---------|
| Bubble Sort        | O(n)             | O(nÂ²)            | O(nÂ²)              | SÃ­      |
| Insertion Sort     | O(n)             | O(nÂ²)            | O(nÂ²)              | SÃ­      |
| Selection Sort     | O(nÂ²)            | O(nÂ²)            | O(nÂ²)              | No      |
| Merge Sort         | O(n log n)       | O(n log n)       | O(n log n)         | SÃ­      |
| Quick Sort         | O(n log n)       | O(n log n)       | O(nÂ²)              | No      |
| Heap Sort          | O(n log n)       | O(n log n)       | O(n log n)         | No      |

### Tip:
- **Estabilidad** significa que los elementos con valores iguales mantienen su orden relativo original.
- QuickSort es muy rÃ¡pido en la prÃ¡ctica, pero su peor caso puede ser problemÃ¡tico si no se elige bien el pivote.
- MergeSort es preferido cuando se necesita un algoritmo estable con buen rendimiento garantizado.




